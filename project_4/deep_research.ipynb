{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe0fb30d",
   "metadata": {},
   "source": [
    "# Project 4: **Build a Deep Research System**\n",
    "Welcome to project 4! For this project, we shift our focus from tool use and agents to *reasoning* models. You will practice state‑of‑the‑art inference‑time scaling methods such as *Chain‑of‑Thought* prompting and *Tree‑of‑Thoughts*, and briefly explore high-levels of training reasoning models using techniques like **STaR**.\n",
    "\n",
    "\n",
    "Finally, you will put everything together to build a *deep research agent* that can browse the web, reason over what it finds, and give structured answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54845369",
   "metadata": {},
   "source": [
    "## Learning Objectives  \n",
    "* Apply common inference‑time scaling methods: **zero‑shot / few‑shot CoT, self‑consistency, sequential decoding, tree‑of‑thoughts**  \n",
    "* Gain intuition for **training** reasoning‑capable models following **STaR** approach \n",
    "* Build a minimal **deep‑research agent** that combines step‑by‑step reasoning with live web search   \n",
    "* Practice extending deep-search to a multi-agent system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a40a86",
   "metadata": {},
   "source": [
    "## Roadmap  \n",
    "1. Environment setup  \n",
    "2. Inference‑time scaling  \n",
    "   2.1 Few‑shot & zero‑shot CoT  \n",
    "   2.2 Self‑consistency\n",
    "   2.3 Sequential revisions  \n",
    "   2.4 Tree‑of‑Thought\n",
    "3. STaR for training models for reasoning  \n",
    "4. Deep-research agent  \n",
    "5. (Optional) Multi-agent deep-research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e480f76",
   "metadata": {},
   "source": [
    "# 1‑ Environment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c2218",
   "metadata": {},
   "source": [
    "## 1.1- Conda environment\n",
    "\n",
    "Before we start coding, you need a reproducible setup. Open a terminal in the same directory as this notebook and run:\n",
    "\n",
    "```bash\n",
    "# Create and activate the conda environment\n",
    "conda env create -f environment.yaml && conda activate deep_research\n",
    "\n",
    "# Register this environment as a Jupyter kernel\n",
    "python -m ipykernel install --user --name=deep_research --display-name \"deep_research\"\n",
    "```\n",
    "Once this is done, you can select \"deep_research\" from the Kernel → Change Kernel menu in Jupyter or VS Code.\n",
    "\n",
    "## 1.2 Ollama setup\n",
    "\n",
    "In this project we use the `llama3.2:3b` and `deepseek-r1:8b` models. You can try other smaller or larger reasoning LLMs such as `qwen2.5:3b-instruct` or `phi4-mini` to compare performance. Explore available models here: https://ollama.com/library.\n",
    "\n",
    "```bash\n",
    "ollama pull llama3.2:3b\n",
    "ollama pull deepseek-r1:8b\n",
    "# Additional small reasoning models to compare\n",
    "# ollama pull qwen2.5:3b-instruct\n",
    "# ollama pull phi4-mini\n",
    "\n",
    "```\n",
    "\n",
    "`ollama pull` downloads the model so you can run it locally without API calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8d1b7",
   "metadata": {},
   "source": [
    "---  \n",
    "# 2‑ Inference‑time scaling\n",
    "\n",
    "Inference-time scaling refers to techniques that make an existing model reason better without retraining it. Instead of changing the model’s weights, we achieve reasoning capability by adjusting how we prompt, sample, or aggregate LLM's outputs.\n",
    "\n",
    "In this section, we’ll explore several inference-time strategies that improve reasoning quality using a non-reasoning base model. You will experiment with and compare methods such as:\n",
    "\n",
    "- Few-shot Chain-of-Thought (CoT)\n",
    "- Zero-shot CoT\n",
    "- Self-consistency\n",
    "- Sequential revision\n",
    "- Tree-of-Thoughts (ToT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d499a",
   "metadata": {},
   "source": [
    "### 2.1: Few‑Shot CoT\n",
    "Few-shot prompting helps a model reason by showing one or multiple examples before asking a new question. By observing the pattern of reasoning and final answers, the model learns how to structure its own reasoning process on the new input.\n",
    "\n",
    "In this exercise, you will create a prompt that includes a few example Q&A pairs demonstrating step-by-step reasoning. Then, you will feed a new question and see the model’s output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "173d73f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break it down step by step:\n",
      "\n",
      "1. The parking lot started with 12 cars.\n",
      "2. 5 more cars arrived, so we add those to the original number:\n",
      "   12 + 5 = 17\n",
      "3. Then, 3 cars left, so we subtract them from the new total:\n",
      "   17 - 3 = 14\n",
      "\n",
      "The answer is 14.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Write a few examples showing reasoning steps\n",
    "# Step 2: Write your new question\n",
    "# Step 3: Concatenate examples + new question into a single prompt\n",
    "# Step 4: Call your Ollama or OpenAI client to get a response from llama3.2:3b # e.g., client.chat.completions.create(...)\n",
    "# Step 5: Print the final answer\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# initialize ollama cliet\n",
    "client = OpenAI(api_key=\"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "\n",
    "# Few-shot examples with step-by-step reasoning\n",
    "few_shot_examples = \"\"\"\n",
    "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls.\n",
    "How many tennis balls does he have now?\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The\n",
    "answer is 11.\n",
    "\n",
    "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples\n",
    "do they have?\n",
    "A: They had 23 apples originally. They used 20 apples. So they had 23 - 20 = 3 apples left. They\n",
    "bought 6 more, so 3 + 6 = 9. The answer is 9.\n",
    "\"\"\"\n",
    "\n",
    "# New question\n",
    "new_question = \"\"\"Q: A parking lot had 12 cars. 5 more cars arrived and then 3 cars left. How many\n",
    "cars are in the parking lot now?\"\"\"\n",
    "\n",
    "# concatenate prompt\n",
    "prompt = few_shot_examples + \"\\n\" + new_question +\"nA:\"\n",
    "\n",
    "# call the model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3.2:3b\", \n",
    "    messages=[{\"role\":\"user\", \"content\": prompt}],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# print the answr\n",
    "print (response.choices[0].message.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e29d9",
   "metadata": {},
   "source": [
    "### (Optional) Few-shot CoT on GPT2\n",
    "GPT-2 is a pre-trained language model without instruction tuning. It continues text rather than answering questions. In this section, you'll try the exact same CoT pattern on GPT-2 and observe what happens. The goal is to test whether few-shot CoT alone can elicit structured reasoning from a non-chat LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8af711f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4202dc9486f41c88cba62bfd47f7a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vnimmagadda\\AppData\\Local\\miniconda3\\envs\\deep_research\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\vnimmagadda\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0c374be59a48e4ba3562442bbab1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd2dae4b6ea4e679f4e70e6b7af8bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be97eb86b0a44f1d9b56629a3d97f7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ddfffd120249b49d384a09d5f39e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c08f996b0c44079a61c6025bd19635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec9992f31204379a68c8bba34d9c8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Greedy Decoding ===\n",
      " Sarah spends 12 dollars. 20 - 20 = 7. Answer: 7\n",
      "\n",
      "Problem: John has 20 dollars and spends 12 dollars. How much does he have left?\n",
      "\n",
      "Solution: John spends 12 dollars. 20 - 20 = 7. Answer\n",
      "\n",
      "=== Sampling (top-k=50) ===\n",
      " Sarah spends 12 dollars. It's not 12, it's 12 = 6.\n",
      "\n",
      "Example 3:\n",
      "Problem: I have a new car and have to drive from one place in the city to another. How many new cars can I buy?\n",
      "\n",
      "=== Sampling (temperature=0.8) ===\n",
      " She spends 12 dollars. The store had 20 dollars. 10 - 12 = 7. Answer: 7\n",
      "\n",
      "Example 3:\n",
      "Problem: An engineer has 40 dollars, and spends 20 dollars to build a new car. How many are he supposed to\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Load GPT-2 text-generation from huggingface (https://huggingface.co/docs/transformers/en/model_doc/gpt2)\n",
    "# Step 2: Write 1–2 few-shot reasoning examples (short, explicit steps + final answer in your own unique format)\n",
    "# Step 3: Append a new test question after the examples to form one prompt string\n",
    "# Step 4: Generate 1–3 completions with different decoding settings (e.g., greedy vs. top-k)\n",
    "# Step 5: Print raw outputs; check if steps are followed and if the final answer is correct\n",
    "\n",
    "# Step 1: Load GPT-2 text-generation from huggingface\n",
    "generator = pipeline('text-generation', model='gpt2', device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Step 2: Write 1-2 few-shot reasoning examples (short, explicit steps + final answer)\n",
    "few_shot_examples = \"\"\"Example 1:\n",
    "Problem: John has 3 apples and buys 4 more. How many does he have?\n",
    "Solution: John starts with 3 apples. He buys 4 more. 3 + 4 = 7. Answer: 7\n",
    "\n",
    "Example 2:\n",
    "Problem: A store had 15 books and sold 8. How many are left?\n",
    "Solution: The store had 15 books. They sold 8. 15 - 8 = 7. Answer: 7\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Append a new test question\n",
    "new_question = \"\"\"Problem: Sarah has 20 dollars and spends 12 dollars. How much does she have left?\n",
    "Solution:\"\"\"\n",
    "\n",
    "prompt = few_shot_examples + new_question\n",
    "\n",
    "# Step 4: Generate with different decoding settings\n",
    "print(\"=== Greedy Decoding ===\")\n",
    "output1 = generator(prompt, max_new_tokens=50, do_sample=False, pad_token_id=50256)\n",
    "print(output1[0]['generated_text'][len(prompt):])\n",
    "\n",
    "print(\"\\n=== Sampling (top-k=50) ===\")\n",
    "output2 = generator(prompt, max_new_tokens=50, do_sample=True, top_k=50, pad_token_id=50256)\n",
    "print(output2[0]['generated_text'][len(prompt):])\n",
    "\n",
    "print(\"\\n=== Sampling (temperature=0.8) ===\")\n",
    "output3 = generator(prompt, max_new_tokens=50, do_sample=True, temperature=0.8, pad_token_id=50256)\n",
    "print(output3[0]['generated_text'][len(prompt):])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adee0e7",
   "metadata": {},
   "source": [
    "### 2.2: Zero‑Shot Chain‑of‑Thought\n",
    "Zero-shot CoT encourages the model to reason without examples by adding a short cue such as “Let’s think step by step.” This simple phrase often activates the model’s latent reasoning ability even when no demonstrations are provided. It serves as a baseline to compare with few-shot and other inference-time scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c444eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find out how many miles the train travels in 2 hours, we need to first determine its speed.\n",
      "\n",
      "The train travels 60 miles in 45 minutes. To make this easier to work with, let's convert the time from minutes to hours:\n",
      "\n",
      "45 minutes = 0.75 hours (since there are 60 minutes in an hour)\n",
      "\n",
      "Now we can find the train's speed by dividing the distance it traveled (60 miles) by the time it took to travel that distance (0.75 hours):\n",
      "\n",
      "Speed = Distance / Time\n",
      "= 60 miles / 0.75 hours\n",
      "= 80 miles per hour\n",
      "\n",
      "So, the train travels at a speed of 80 miles per hour.\n",
      "\n",
      "Now we need to find out how many miles the train will travel in 2 hours:\n",
      "\n",
      "Distance = Speed x Time\n",
      "= 80 miles/hour x 2 hours\n",
      "= 160 miles\n",
      "\n",
      "Therefore, the train will travel 160 miles in 2 hours.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Step 1: Write the question and a zero-shot CoT cue (e.g., \"Let's think step by step.\")\n",
    "# Step 2: Build a single prompt string that includes brief role guidance plus the question\n",
    "# Step 3: Call your Ollama or OpenAI client to get a response from llama3.2:3b  # e.g., client.chat.completions.create(...)\n",
    "# Step 4: Print the chain and the final answer\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=\"ollama\", base_url=\"http://localhost:11434/v1\")\n",
    "\n",
    "# Question with zero-shot CoT cue\n",
    "question = \"If a train travels 60 miles in 45 minutes, how many miles does it travel in 2 hours?\"\n",
    "prompt = f\"You are a helpful assistant. {question}\\n\\nLet's think step by step.\"\n",
    "\n",
    "# call the model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3.2:3b\",\n",
    "    messages=[{\"role\":\"user\", \"content\":prompt}],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# print the chain and final ansxwer\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686708da",
   "metadata": {},
   "source": [
    "### 2.3 Self‑Consistency\n",
    "Self-consistency enhances reasoning accuracy by sampling multiple independent reasoning paths for the same question instead of relying on a single deterministic answer. Each run may follow a slightly different logical chain, and the diversity helps correct individual mistakes. After generating several reasoning traces, you then aggregate the final answers using majority voting.\n",
    "\n",
    "This approach is especially useful when tasks involve multi-step reasoning or arithmetic, where single-path outputs may be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2fb325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10 reasoning paths...\n",
      "\n",
      "Run 1: Answer = 12\n",
      "Run 2: Answer = 12\n",
      "Run 3: Answer = 12\n",
      "Run 4: Answer = 12\n",
      "Run 5: Answer = 144\n",
      "Run 6: Answer = 12\n",
      "Run 7: Answer = 12\n",
      "Run 8: Answer = 12\n",
      "Run 9: Answer = 12\n",
      "Run 10: Answer = 12\n",
      "Votes: Counter({'12': 9, '144': 1})\n",
      "Chosen answer: 12\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import re, collections\n",
    "\n",
    "client = OpenAI(api_key = \"ollama\", base_url = \"http://localhost:11434/v1\")\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def cot_answer(question, temperature=1.0):    \n",
    "    # Generate a step-by-step reasoning chain for the given question and extract the final answer.\n",
    "    prompt = f\"{question}\\n\\nLet's think step by step.\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    reasoning = response.choices[0].message.content\n",
    "\n",
    "    # Extract final answer (look for patterns like \"Answer: X\" or \"The answer is X\")\n",
    "    answer_match = re.search(r'(?:answer is|answer:|Answer:)\\s*(\\d+)', reasoning, re.IGNORECASE)\n",
    "    if answer_match:\n",
    "        return reasoning, answer_match.group(1)\n",
    "\n",
    "    # Fallback: extract last number\n",
    "    numbers = re.findall(r'\\b\\d+\\b', reasoning)\n",
    "    final_answer = numbers[-1] if numbers else \"unknown\"\n",
    "\n",
    "    return reasoning, final_answer\n",
    "\n",
    "def self_consistent(question, n=10):\n",
    "    # Run multiple reasoning chains and select the most frequent final answer by majority voting.\n",
    "    answers = []\n",
    "\n",
    "    print(f\"Generating {n} reasoning paths...\\n\")\n",
    "\n",
    "    for i in range(n):\n",
    "        reasoning, answer = cot_answer(question, temperature=0.8)\n",
    "        answers.append(answer)\n",
    "        print(f\"Run {i+1}: Answer = {answer}\")\n",
    "\n",
    "    # Count votes\n",
    "    counter = collections.Counter(answers)\n",
    "    winner = counter.most_common(1)[0][0]\n",
    "\n",
    "    return winner, counter\n",
    "\n",
    "\n",
    "question = \"What is the square root of 144?\"\n",
    "winner, counter = self_consistent(question)\n",
    "print(\"Votes:\", counter)\n",
    "print(\"Chosen answer:\", winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bea715",
   "metadata": {},
   "source": [
    "### 2.4: Sequential Revision\n",
    "\n",
    "Sequential revision iteratively improves an answer by generating a first draft, critiquing it, and producing revised drafts that condition on prior answers. Each round should be short and focused, so improvements accumulate without drifting from the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07e5859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Initial Draft ===\n",
      "The main causes of climate change include:\n",
      "\n",
      "1. **Greenhouse gas emissions**: Mainly caused by burning fossil fuels (coal, oil, and gas), deforestation, and land-use changes.\n",
      "2. **Deforestation**: Leading to loss of carbon sinks and increased greenhouse gas emissions.\n",
      "3. **Agriculture**: Especially beef and sheep production, which leads to methane emissions.\n",
      "4. **Industrial processes**: Such as cement production and the manufacturing of steel.\n",
      "\n",
      "Potential solutions include:\n",
      "\n",
      "1. **Transitioning to renewable energy**: Shifting from fossil fuels to solar, wind, and hydroelectric power.\n",
      "2. **Increasing energy efficiency**: Improving insulation, using smart grids, and optimizing industrial processes.\n",
      "3. **Electrifying transportation**: Promoting electric vehicles and public transport.\n",
      "4. **Carbon capture and storage**: Implementing technologies that capture CO2 emissions from power plants and industrial processes.\n",
      "5. **Sustainable land use**: Implementing reforestation efforts, agroforestry, and organic farming practices.\n",
      "6. **Climate-resilient infrastructure**: Building sea walls, levees, and green roofs to protect communities from climate-related disasters.\n",
      "7. **Reducing meat consumption**: By adopting plant-based diets or reducing meat intake, we can decrease agricultural greenhouse gas emissions.\n",
      "\n",
      "Implementing these solutions requires a coordinated global effort, with governments, industries, and individuals working together to reduce greenhouse gas emissions and mitigate the effects of climate change.\n",
      "\n",
      "=== Revision 1 ===\n",
      "=== Revision 2 ===\n",
      "**The Main Causes and Potential Solutions for Climate Change**\n",
      "\n",
      "Climate change is a complex and pressing issue that requires immediate attention and action from individuals, industries, and governments worldwide. The following section outlines the main causes of climate change and potential solutions to mitigate its effects.\n",
      "\n",
      "**Main Causes of Climate Change:**\n",
      "\n",
      "1. **Greenhouse Gas Emissions**: Burning fossil fuels (coal, oil, and gas), deforestation, and land-use changes are the primary sources of greenhouse gas emissions, primarily carbon dioxide (CO2).\n",
      "2. **Deforestation**: The clearing of forests for agriculture, urbanization, and logging releases stored carbon into the atmosphere and reduces the ability of forests to act as carbon sinks.\n",
      "3. **Agriculture**: Livestock farming, especially beef and sheep production, leads to methane emissions, while fertilizers and plows release nitrous oxide (N2O), both potent greenhouse gases.\n",
      "4. **Industrial Processes**: Cement production and steel manufacturing are significant sources of CO2 emissions.\n",
      "\n",
      "**Additional Causes:**\n",
      "\n",
      "1. **Population Growth**: As the global population grows, so does energy demand, leading to increased greenhouse gas emissions from transportation, industry, and agriculture.\n",
      "2. **Urbanization**: The growth of cities leads to increased energy consumption, transportation emissions, and waste management issues.\n",
      "3. **Consumption Patterns**: Globalization has led to increased consumption patterns, especially in developed countries, contributing to higher energy demands and resource usage.\n",
      "\n",
      "**Potential Solutions:**\n",
      "\n",
      "1. **Transitioning to Renewable Energy**: Shifting from fossil fuels to solar, wind, hydroelectric power, and other low-carbon energy sources can significantly reduce greenhouse gas emissions.\n",
      "2. **Increasing Energy Efficiency**: Improving insulation, using smart grids, optimizing industrial processes, and promoting energy-efficient technologies can reduce energy consumption and emissions.\n",
      "3. **Electrifying Transportation**: Promoting electric vehicles, public transport, and non-motorized transportation can decrease dependence on fossil fuels and lower emissions.\n",
      "4. **Carbon Capture and Storage (CCS)**: Implementing CCS technologies can capture CO2 emissions from power plants and industrial processes, reducing emissions and storing the gas underground.\n",
      "5. **Sustainable Land Use**: Implementing reforestation efforts, agroforestry, organic farming practices, and regenerative agriculture can sequester carbon dioxide from the atmosphere and improve soil health.\n",
      "6. **Climate-Resilient Infrastructure**: Building sea walls, levees, green roofs, and other climate-resilient infrastructure can protect communities from the impacts of climate-related disasters.\n",
      "7. **Reducing Meat Consumption**: Adopting plant-based diets or reducing meat intake can decrease agricultural greenhouse gas emissions by up to 50%.\n",
      "8. **Circular Economy**: Implementing a circular economy approach can reduce waste, promote recycling, and encourage sustainable consumption patterns.\n",
      "\n",
      "**Implementation and Collaboration:**\n",
      "\n",
      "Implementing these solutions requires a coordinated global effort, with governments, industries, and individuals working together to:\n",
      "\n",
      "1. Set ambitious emission reduction targets\n",
      "2. Develop and deploy low-carbon technologies\n",
      "3. Promote sustainable land use practices\n",
      "4. Enhance climate resilience in vulnerable communities\n",
      "5. Foster international cooperation and knowledge sharing\n",
      "\n",
      "By combining these solutions and working together, we can mitigate the effects of climate change, ensure a livable future for all, and create a more sustainable world.\n",
      "\n",
      "=== Final Answer ===\n",
      "**The Main Causes and Potential Solutions for Climate Change**\n",
      "\n",
      "Climate change is a complex and pressing issue that requires immediate attention and action from individuals, industries, and governments worldwide. The following section outlines the main causes of climate change and potential solutions to mitigate its effects.\n",
      "\n",
      "**Main Causes of Climate Change:**\n",
      "\n",
      "1. **Greenhouse Gas Emissions**: Burning fossil fuels (coal, oil, and gas), deforestation, and land-use changes are the primary sources of greenhouse gas emissions, primarily carbon dioxide (CO2).\n",
      "2. **Deforestation**: The clearing of forests for agriculture, urbanization, and logging releases stored carbon into the atmosphere and reduces the ability of forests to act as carbon sinks.\n",
      "3. **Agriculture**: Livestock farming, especially beef and sheep production, leads to methane emissions, while fertilizers and plows release nitrous oxide (N2O), both potent greenhouse gases.\n",
      "4. **Industrial Processes**: Cement production and steel manufacturing are significant sources of CO2 emissions.\n",
      "\n",
      "**Additional Causes:**\n",
      "\n",
      "1. **Population Growth**: As the global population grows, so does energy demand, leading to increased greenhouse gas emissions from transportation, industry, and agriculture.\n",
      "2. **Urbanization**: The growth of cities leads to increased energy consumption, transportation emissions, and waste management issues.\n",
      "3. **Consumption Patterns**: Globalization has led to increased consumption patterns, especially in developed countries, contributing to higher energy demands and resource usage.\n",
      "\n",
      "**Potential Solutions:**\n",
      "\n",
      "1. **Transitioning to Renewable Energy**: Shifting from fossil fuels to solar, wind, hydroelectric power, and other low-carbon energy sources can significantly reduce greenhouse gas emissions.\n",
      "2. **Increasing Energy Efficiency**: Improving insulation, using smart grids, optimizing industrial processes, and promoting energy-efficient technologies can reduce energy consumption and emissions.\n",
      "3. **Electrifying Transportation**: Promoting electric vehicles, public transport, and non-motorized transportation can decrease dependence on fossil fuels and lower emissions.\n",
      "4. **Carbon Capture and Storage (CCS)**: Implementing CCS technologies can capture CO2 emissions from power plants and industrial processes, reducing emissions and storing the gas underground.\n",
      "5. **Sustainable Land Use**: Implementing reforestation efforts, agroforestry, organic farming practices, and regenerative agriculture can sequester carbon dioxide from the atmosphere and improve soil health.\n",
      "6. **Climate-Resilient Infrastructure**: Building sea walls, levees, green roofs, and other climate-resilient infrastructure can protect communities from the impacts of climate-related disasters.\n",
      "7. **Reducing Meat Consumption**: Adopting plant-based diets or reducing meat intake can decrease agricultural greenhouse gas emissions by up to 50%.\n",
      "8. **Circular Economy**: Implementing a circular economy approach can reduce waste, promote recycling, and encourage sustainable consumption patterns.\n",
      "\n",
      "**Implementation and Collaboration:**\n",
      "\n",
      "Implementing these solutions requires a coordinated global effort, with governments, industries, and individuals working together to:\n",
      "\n",
      "1. Set ambitious emission reduction targets\n",
      "2. Develop and deploy low-carbon technologies\n",
      "3. Promote sustainable land use practices\n",
      "4. Enhance climate resilience in vulnerable communities\n",
      "5. Foster international cooperation and knowledge sharing\n",
      "\n",
      "By combining these solutions and working together, we can mitigate the effects of climate change, ensure a livable future for all, and create a more sustainable world.\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def sequential_revision(question: str, max_steps: int = 3) -> str:\n",
    "    # Generate an initial draft answer, then iteratively refine it by conditioning each revision on the previous one.\n",
    "    # Step 1: Ask the model to produce the first draft for the given question\n",
    "    # Step 2: Loop for max_steps-1 times, each time feeding the last draft back to the model with a request to revise\n",
    "    # Step 3: Print each draft to observe how the answer evolves\n",
    "    # Step 4: Return the final improved draft\n",
    "\n",
    "    # Generate an initial draft answer, then iteratively refine it by conditioning each revision on the previous one.\n",
    "\n",
    "    # Step 1: Generate the first draft\n",
    "    print(\"=== Initial Draft ===\")\n",
    "    prompt = f\"{question}\\n\\nProvide a clear and concise answer.\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    draft = response.choices[0].message.content\n",
    "    print(draft)\n",
    "    print()\n",
    "\n",
    "    # Step 2: Iteratively revise the draft\n",
    "    for step in range(1, max_steps):\n",
    "        print(f\"=== Revision {step} ===\")\n",
    "\n",
    "        revision_prompt = f\"\"\"Question: {question}\n",
    "\n",
    "    Previous answer:\n",
    "    {draft}\n",
    "\n",
    "    Please review the previous answer and improve it. Make it more accurate, complete, and well-structured. Provide the revised    \n",
    "    answer.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": revision_prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    draft = response.choices[0].message.content\n",
    "    print(draft)\n",
    "    print()\n",
    "\n",
    "    # Step 4: Return the final improved draft\n",
    "    return draft\n",
    "\n",
    "\n",
    "# Step 1: Define a question that benefits from multi-step reasoning\n",
    "# Step 2: Call sequential_revision(question, max_steps)\n",
    "# Step 3: Print the final output\n",
    "# Step 1: Define a question that benefits from multi-step reasoning\n",
    "question = \"What are the main causes and potential solutions for climate change?\"\n",
    "\n",
    "# Step 2: Call sequential_revision\n",
    "final_answer = sequential_revision(question, max_steps=3)\n",
    "\n",
    "# Step 3: Print the final output\n",
    "print(\"=== Final Answer ===\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9319ee8",
   "metadata": {},
   "source": [
    "### 2.5 Tree‑of‑Thoughts\n",
    "Tree-of-Thoughts reframes reasoning as a search process rather than a single forward chain.\n",
    "Instead of producing one linear sequence of thoughts, the model generates multiple candidate thoughts at each step, evaluates their promise, and then expands only the best few. This allows exploration of different reasoning paths before committing to a final answer, similar to how humans brainstorm, prune, and refine ideas.\n",
    "\n",
    "\n",
    "In this section, you’ll experiment with two simplified versions of ToT:\n",
    "1. Word Ladder puzzle solver: a small example where each “thought” is a candidate word transition.\n",
    "2. Generic ToT search (depth 2, width 2): a minimal logic to expand, evaluate, and select reasoning branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d047801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hit', 'hot', 'dot', 'dog', 'cog']\n"
     ]
    }
   ],
   "source": [
    "###### Word Ladder Puzzle ##########\n",
    "\n",
    "def neighbors(word, vocabulary):\n",
    "    # Generate all valid one-letter mutations of 'word' that exist in 'vocabulary' and return them.\n",
    "    # Generate all valid one-letter mutations of 'word' that exist in 'vocabulary' and return them.\n",
    "    result = []\n",
    "    for i in range(len(word)):\n",
    "        for c in 'abcdefghijklmnopqrstuvwxyz':\n",
    "            if c != word[i]:\n",
    "                mutated = word[:i] + c + word[i+1:]\n",
    "                if mutated in vocabulary:\n",
    "                    result.append(mutated)\n",
    "    return result    \n",
    "\n",
    "\n",
    "def tree_of_thought(start, goal, vocab, max_depth=5, beam_width=4):\n",
    "    # Search over partial thoughts (paths) using a small beam.\n",
    "    # Step 1: Initialize the frontier with a single path [start]\n",
    "    # Step 2: For each depth, expand each path by one neighbor from 'neighbors'\n",
    "    # Step 3: Score paths by edit distance between last word and 'goal' (smaller is better)\n",
    "    # Step 4: Keep the top 'beam_width' paths and stop early if any reaches 'goal'\n",
    "    # Step 5: Return the best goal-reaching path or None\n",
    "\n",
    "    # Search over partial thoughts (paths) using a small beam.\n",
    "    # Step 1: Initialize the frontier with a single path [start]\n",
    "    frontier = [[start]]\n",
    "\n",
    "    # Step 2: For each depth, expand each path by one neighbor\n",
    "    for depth in range(max_depth):\n",
    "        new_frontier = []\n",
    "\n",
    "        # Expand each path in the frontier\n",
    "        for path in frontier:\n",
    "            last_word = path[-1]\n",
    "\n",
    "            # Step 4: Check if we reached the goal\n",
    "            if last_word == goal:\n",
    "                return path\n",
    "\n",
    "            # Generate neighbors\n",
    "            for neighbor in neighbors(last_word, vocab):\n",
    "                if neighbor not in path:  # Avoid cycles\n",
    "                    new_frontier.append(path + [neighbor])\n",
    "\n",
    "        # Step 3: Score paths by edit distance (smaller is better)\n",
    "        def edit_distance(w1, w2):\n",
    "            return sum(c1 != c2 for c1, c2 in zip(w1, w2))\n",
    "\n",
    "        new_frontier.sort(key=lambda p: edit_distance(p[-1], goal))\n",
    "\n",
    "        # Keep only top beam_width paths\n",
    "        frontier = new_frontier[:beam_width]\n",
    "\n",
    "        if not frontier:\n",
    "            break\n",
    "\n",
    "    # Step 5: Return None if no solution found\n",
    "    return None\n",
    "\n",
    "\n",
    "vocab = {\"hit\",\"dot\",\"cog\",\"log\",\"dog\",\"lot\",\"lit\",\"hot\"}\n",
    "print(tree_of_thought(\"hit\", \"cog\", vocab)) # one candidate solution: ['hit', 'hot', 'dot', 'dog', 'cog']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89067302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Depth 1 ===\n",
      "Path 1 (score 6):\n",
      "**Define the Workshop's Focus**: Identify the specific area of science to focus on, such as physics, biology, chemistry, or environmental science. This will help guide the development of activities, experiments, and materials.\n",
      "\n",
      "Path 2 (score 6):\n",
      "**Develop an Activity Framework**: Sketch out a rough outline of the workshop's structure, including:\n",
      "\n",
      "\n",
      "=== Depth 2 ===\n",
      "Path 1 (score 6):\n",
      "**Define the Workshop's Focus**: Identify the specific area of science to focus on, such as physics, biology, chemistry, or environmental science. This will help guide the development of activities, experiments, and materials.\n",
      "**Conduct a Target Audience Research Session**: Host a focus group or survey with parents, teachers, or youth leaders who have experience organizing science workshops for 12-year-olds. This will help identify their expectations, interests, and levels of scientific knowledge, allowing for the development of customized activities and materials that cater to this age group.\n",
      "\n",
      "Path 2 (score 6):\n",
      "**Define the Workshop's Focus**: Identify the specific area of science to focus on, such as physics, biology, chemistry, or environmental science. This will help guide the development of activities, experiments, and materials.\n",
      "**Brainstorm Workshop Activity Ideas**: Collaborate with science educators, experts in environmental science, or experienced youth workshop leaders to generate a list of engaging, hands-on activity ideas that fit within the chosen area of focus (e.g., physics, biology, chemistry). This will help create a preliminary schedule and ensure that the activities are both fun and scientifically accurate.\n",
      "\n",
      "Best solution (score 6):\n",
      "**Define the Workshop's Focus**: Identify the specific area of science to focus on, such as physics, biology, chemistry, or environmental science. This will help guide the development of activities, experiments, and materials.\n",
      "**Conduct a Target Audience Research Session**: Host a focus group or survey with parents, teachers, or youth leaders who have experience organizing science workshops for 12-year-olds. This will help identify their expectations, interests, and levels of scientific knowledge, allowing for the development of customized activities and materials that cater to this age group.\n"
     ]
    }
   ],
   "source": [
    "###### Generic ToT Search ##########\n",
    "\n",
    "import re\n",
    "\n",
    "MODEL = \"llama3.2:3b\"\n",
    "\n",
    "def propose_thoughts(question, state, k=2):\n",
    "    # Propose up to k next “thoughts” that extend the current partial solution/state.\n",
    "    # Steps: build a short prompt with problem + current state; call your client with n=k. Then return a list of stripped strings (≤ k).\n",
    "\n",
    "    # Propose up to k next \"thoughts\" that extend the current partial solution/state.\n",
    "    prompt = f\"\"\"Problem: {question}\n",
    "\n",
    "    Current progress:\n",
    "    {state if state else 'Just starting...'}\n",
    "\n",
    "    Propose {k} different next steps or ideas to continue solving this problem. Be brief and specific.\n",
    "    List them as:\n",
    "    1. [first idea]\n",
    "    2. [second idea]\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.8\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    # Extract numbered items\n",
    "    thoughts = re.findall(r'\\d+\\.\\s*(.+)', text)\n",
    "\n",
    "    return thoughts[:k]\n",
    "\n",
    "\n",
    "def score_state(question, state):\n",
    "    # Score how promising a partial solution is on a 1–10 scale (higher is better).\n",
    "    # Steps: build a rating prompt; call the model; parse the first integer 1–10;\n",
    "\n",
    "    # Score how promising a partial solution is on a 1–10 scale (higher is better).\n",
    "    prompt = f\"\"\"Problem: {question}\n",
    "\n",
    "    Current progress:\n",
    "    {state}\n",
    "\n",
    "    Rate how promising this progress is for solving the problem on a scale of 1-10, where 10 is very promising.\n",
    "    Respond with just a single number between 1 and 10.\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content.strip()\n",
    "    # Extract first number\n",
    "    match = re.search(r'\\b([1-9]|10)\\b', text)\n",
    "\n",
    "    return int(match.group(1)) if match else 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tree_of_thoughts(question, depth=2, width=2):\n",
    "    # Run a tiny ToT search: expand states with propose_thoughts, score with score_state, keep top-k at each depth.\n",
    "    # Steps: initialize frontier=[(\"\", 0)]; for each depth, expand each state with k=width thoughts; score each; sort by score desc; keep top 'width'; return best state and score.\n",
    "\n",
    "    # Run a tiny ToT search: expand states, score them, keep top-k at each depth.\n",
    "    frontier = [(\"\", 0)]  # (state, score)\n",
    "\n",
    "    for d in range(depth):\n",
    "        new_frontier = []\n",
    "\n",
    "        for state, _ in frontier:\n",
    "            # Propose k=width new thoughts\n",
    "            thoughts = propose_thoughts(question, state, k=width)\n",
    "\n",
    "            # Score each new state\n",
    "            for thought in thoughts:\n",
    "                new_state = state + \"\\n\" + thought if state else thought\n",
    "                score = score_state(question, new_state)\n",
    "                new_frontier.append((new_state, score))\n",
    "\n",
    "        # Sort by score (descending) and keep top width\n",
    "        new_frontier.sort(key=lambda x: x[1], reverse=True)\n",
    "        frontier = new_frontier[:width]\n",
    "\n",
    "        print(f\"\\n=== Depth {d+1} ===\")\n",
    "        for i, (s, sc) in enumerate(frontier, 1):\n",
    "            print(f\"Path {i} (score {sc}):\\n{s}\\n\")\n",
    "\n",
    "    # Return best state and score\n",
    "    return frontier[0]\n",
    "\n",
    "\n",
    "question = \"Design a plan for a weekend science workshop for 12-year-olds.\"\n",
    "solution, score = tree_of_thoughts(question)\n",
    "\n",
    "print(f\"Best solution (score {score}):\\n{solution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc38f6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 3‑ Training Models for Reasoning\n",
    "\n",
    "### 3.1: CoT Training\n",
    "Chain-of-Thought (CoT) training conditions the model on explicit rationales during fine-tuning. Instead of teaching the model to output only the final answer, we train on (question, rationale, answer) so the model learns to internalize multi-step reasoning patterns. A practical recipe is STaR (Self-Taught Reasoner), which uses a stronger teacher model to bootstrap rationales that a smaller student can learn from.\n",
    "\n",
    "For tasks that require multi-hop reasoning, models fine-tuned on rationales often achieve higher accuracy and are more stable at inference time than models trained on direct answers only. \n",
    "\n",
    "Training a full language model is beyond the scope of this notebook, but here is the high-level workflow followed by a short pseudocode:\n",
    "- Collect questions: Prepare a dataset of questions and correct answers.\n",
    "- Generate rationales: Use a strong LLM to produce step-by-step reasoning ending with the correct answer.\n",
    "- Filter and clean: Discard incorrect or low-quality rationales.\n",
    "- Prepare training data: Format triples (question, rationale, answer) for supervised fine-tuning.\n",
    "- Fine-tune: Fine-tune the LLM on rationales.\n",
    "- Iterate: Refine prompts, improve data quality, and retrain for stronger reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode (STaR loop)\n",
    "# for round in 1 ... iters:\n",
    "    # STEP 1: self-generate reasoning (teacher creates rationale + answer)\n",
    "    # STEP 2: keep only correct, high-quality traces\n",
    "    # STEP 3: fine-tune student on (question, rationale, answer) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b53c70",
   "metadata": {},
   "source": [
    "### 3.2: ORM vs PRM + RL\n",
    "Training a Reward Model (RM) allows large language models to be improved through reinforcement learning (RL). Instead of fine-tuning directly on examples, we train a separate model that can score or rank model outputs, and use those scores as feedback signals to refine the policy model.\n",
    "\n",
    "Two main reward modeling approaches are ORM (predicts a scalar reward for the final answer) and PRM (evaluates the reasoning steps instead of just the outcome)\n",
    "\n",
    "\n",
    "\n",
    "| Approach | Typical loss | When to use |\n",
    "|-----------|-------------|-------------|\n",
    "|*Outcome Reward Model* | Predict scalar reward | Easy to collect training data using verifiers |\n",
    "|*Process Reward Model* | Predict rewards per step | Difficult to collect training data but more accurate |\n",
    "| *RLHF* | Use RM as reward in **RL** fine‑tuning | Aligns policy with human signals | Aligns model policy with human or synthetic preferences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for round = 1 ... iters:\n",
    "    # STEP 1:  Generate reasoning\n",
    "        # sample a minibatch of questions\n",
    "        # policy roll‑out (actions + log‑probs)\n",
    "    # STEP 2:  Score the trajectory\n",
    "        # ORM: scalar reward for the final answer / PRM: scalar reward for the thought process\n",
    "    # STEP 3:  Reinforce the policy (PPO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a81a6",
   "metadata": {},
   "source": [
    "---  \n",
    "# 4‑ A Deep Research Agent\n",
    "\n",
    "A deep-research agent pairs a reasoning model (e.g., deepseek-r1) with external tools for web search and retrieval. We will follow the ReAct pattern: the model writes short thoughts, decides when to call tools, reads observations, and continues reasoning until it can answer or reaches a step limit.\n",
    "\n",
    "We now combine a **search tool** with a reasoning model (e.g., `deepseek-r1`) in a multi-step setup. We follow the *ReAct* pattern (reason → tool → observation):\n",
    "\n",
    "1. The model reasoins and decides to use tools\n",
    "2. The agent searches and feed condensed snippets back as context\n",
    "3. Iterate until the model answers or hits a step limit\n",
    "\n",
    "We use `AgentType.OPENAI_FUNCTIONS`, which hides the loop inside the LangChain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd1e1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddgs import DDGS\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def ddg_search(query: str, k: int = 5) -> str:\n",
    "    # Use DDGS to run a simple web search and return joined snippets.\n",
    "    with DDGS() as ddgs:\n",
    "        results = list(ddgs.text(query, max_results=k))\n",
    "\n",
    "    # Extract and join snippets\n",
    "    snippets = [f\"{r['title']}: {r['body']}\" for r in results]\n",
    "    return \"\\n\\n\".join(snippets)\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"DuckDuckGo Search\",\n",
    "    func=ddg_search,\n",
    "    description=\"Search the public web. Input: a plain English query. Returns: concatenated snippets.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "418a0d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vnimmagadda\\AppData\\Local\\Temp\\ipykernel_52516\\2075805061.py:8: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=MODEL, temperature=0.7)\n",
      "C:\\Users\\vnimmagadda\\AppData\\Local\\Temp\\ipykernel_52516\\2075805061.py:11: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent([search_tool], llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
      "C:\\Users\\vnimmagadda\\AppData\\Local\\Temp\\ipykernel_52516\\2075805061.py:19: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = agent.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Question: What are the best resources to learn machine learning in 2025?\n",
      "============================================================\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: I need to find the best resources for learning machine learning as of 2025. Since I can't access real-time information, I should first search for current trends and recommendations that might be relevant for the future. I'll use the DuckDuckGo search tool to find articles and lists about the best ML learning resources around now.\n",
      "Action: DuckDuckGo Search\n",
      "Action Input: \"best resources to learn machine learning 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m10 Online Places to Learn Machine Learning in 2024: Whether you're looking to start a career in data science or simply improve your coding skills, learningmachinelearning is a smart investment. Here’s a list of the Top 10 Best Places to LearnMachineLearning in 2024 to help guide your journey!\n",
      "\n",
      "100+ Best Resources to Learn Machine Learning in 2024: Nov 25, 2024 · This list of 100+ resources is designed to be your comprehensive roadmap for learningmachinelearning in 2024. Whether you’re an aspiring ML engineer, a data scientist, or simply curious about the technology driving the future, these resources will guide you toward success.\n",
      "\n",
      "Guide to Learning Machine Learning in 2024 (With Resources): Sep 9, 2023 · This article is a beginner-friendly guide to learningmachinelearning in 2024 for FREE. I will be giving you a roadmap and some advice that I wish someone had given me when I was a total...\n",
      "\n",
      "How to Learn Machine Learning in 2024 - GeeksforGeeks: Jul 23, 2025 · By the end of this article, you’ll have a clear understanding of how to approach learningmachinelearning in 2024, equipped with the knowledge and resources to succeed.\n",
      "\n",
      "Explore the world of artificial ... - MIT Open Learning: May 23, 2024 · Through MIT OpenCourseWare, MITx, and MIT xPRO learn about machinelearning, computational thinking, deepfakes, and more.Photo: iStockWith the rise of artificial intelligence, the job landscape is changing — rapidly. MIT Open Learning offers online courses and resources straight from the MIT classroom that are designed to empower learners and professionals across industries with the ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "Okay, let's think through this step by step.\n",
      "\n",
      "First, the user is asking for the \"best\" resources to learn Machine Learning specifically for the year 2025. This is interesting because 2025 hasn't happened yet! I don't have real-time data or predictions about the exact resources that will be considered \"best\" then. However, I can base my answer on current trends, highly-regarded resources that are likely to remain relevant, and the types of platforms and content that are emerging or expanding rapidly in the ML field.\n",
      "\n",
      "I should focus on resources that are currently strong, foundational, and have a track record of being updated and relevant. These are the kinds of resources that will probably still be the go-to options in 2025. The answer should be structured to guide someone effectively, covering different learning styles (theory, practice, community) and levels (beginner, intermediate).\n",
      "\n",
      "Looking at the search results I found, they point towards several strong indicators. They mention platforms like GeeksforGeeks and MIT Open Learning, which offer structured courses and articles. They also reference comprehensive lists of resources, indicating that curated collections are valuable. The search results also mention foundational concepts, coding practice, and staying updated with research, which are all key aspects of learning ML effectively.\n",
      "\n",
      "Therefore, the plan is to synthesize information from these sources and other known best practices, focusing on foundational courses, hands-on projects, staying updated with the latest developments, and engaging with the community. The goal is to provide a curated list and roadmap that aligns with current recommendations and is likely to remain relevant and effective in the near future, including 2025.\n",
      "\n",
      "Here is the final answer based on current information and logical extrapolation for relevance in 2025:\n",
      "\n",
      "Final Answer: Based on current trends and highly-regarded resources (as of late 2024), the best ways to learn machine learning in 2025 will likely build upon these foundations. Here's a curated roadmap:\n",
      "\n",
      "1.  **Foundational Concepts & Courses (Essential):**\n",
      "    *   **Coursera/edX (Stanford, MIT, Caltech, etc.):** Start with the classic Andrew Ng course on Coursera (likely updated further) or explore specialized courses from top universities on edX. These platforms offer rigorous, structured learning with assignments.\n",
      "    *   **Fast.ai:** Follows a unique top-down approach, starting with powerful applications before diving into theory. Their Practical Deep Learning for Coders course is particularly relevant for 2025 given the rise of generative AI. Their free content is excellent.\n",
      "    *   **Google's ML Crash Course (with TensorFlow):** Excellent hands-on introduction specifically focused on TensorFlow, a major ML framework.\n",
      "    *   **Microsoft Learn:** Free, interactive, modular learning paths covering various ML and AI areas.\n",
      "\n",
      "2.  **Hands-on Practice & Projects (Crucial):**\n",
      "    *   **Kaggle:** Engage with datasets, participate in competitions, and learn from others' kernels. This is arguably the most effective way to gain practical experience and see real-world applications evolving towards 2025 trends.\n",
      "    *   **TensorFlow, PyTorch, Scikit-learn:** Learn by doing. Build small projects using these core frameworks. Expect ongoing updates and new features relevant to 2025 applications (e.g., more efficient models, better distributed training).\n",
      "    *   **Hugging Face:** Essential for learning state-of-the-art deep learning, particularly in NLP and vision, which heavily influence generative AI trends heading towards 2025.\n",
      "\n",
      "3.  **Advanced Topics & Cutting-Edge (For Deeper Dive):**\n",
      "    *   **Specialized MOOCs/University Courses:** Look for courses focusing on specific areas like Deep Learning, Computer Vision, Natural Language Processing, or MLOps (Machine Learning Operations), which will be increasingly important as ML systems scale.\n",
      "    *   **Research Papers (via arXiv, Google Scholar):** Stay informed about the latest advancements. While challenging, reading summaries and recent papers (especially in areas like Generative AI, Transformers, or RLHF) will be key for understanding the forefront heading towards 2025.\n",
      "\n",
      "4.  **Community & Further Learning:**\n",
      "    *   **Reddit (r/MachineLearning, r/datascience):** Engage with discussions, get answers to specific questions, and stay updated on industry news and trends.\n",
      "    *   **YouTube Channels (e.g., Google I/O, PyCon, 3Blue1Brown):** Visual explanations and talks from experts help solidify understanding and provide insights into industry trends relevant to 2025.\n",
      "\n",
      "This roadmap combines structured learning, practical application, and staying current with the rapidly evolving field, positioning learners well for mastering machine learning by 2025. Remember to supplement with coding practice and project building!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "============================================================\n",
      "Final Answer:\n",
      "Based on current trends and highly-regarded resources (as of late 2024), the best ways to learn machine learning in 2025 will likely build upon these foundations. Here's a curated roadmap:\n",
      "\n",
      "1.  **Foundational Concepts & Courses (Essential):**\n",
      "    *   **Coursera/edX (Stanford, MIT, Caltech, etc.):** Start with the classic Andrew Ng course on Coursera (likely updated further) or explore specialized courses from top universities on edX. These platforms offer rigorous, structured learning with assignments.\n",
      "    *   **Fast.ai:** Follows a unique top-down approach, starting with powerful applications before diving into theory. Their Practical Deep Learning for Coders course is particularly relevant for 2025 given the rise of generative AI. Their free content is excellent.\n",
      "    *   **Google's ML Crash Course (with TensorFlow):** Excellent hands-on introduction specifically focused on TensorFlow, a major ML framework.\n",
      "    *   **Microsoft Learn:** Free, interactive, modular learning paths covering various ML and AI areas.\n",
      "\n",
      "2.  **Hands-on Practice & Projects (Crucial):**\n",
      "    *   **Kaggle:** Engage with datasets, participate in competitions, and learn from others' kernels. This is arguably the most effective way to gain practical experience and see real-world applications evolving towards 2025 trends.\n",
      "    *   **TensorFlow, PyTorch, Scikit-learn:** Learn by doing. Build small projects using these core frameworks. Expect ongoing updates and new features relevant to 2025 applications (e.g., more efficient models, better distributed training).\n",
      "    *   **Hugging Face:** Essential for learning state-of-the-art deep learning, particularly in NLP and vision, which heavily influence generative AI trends heading towards 2025.\n",
      "\n",
      "3.  **Advanced Topics & Cutting-Edge (For Deeper Dive):**\n",
      "    *   **Specialized MOOCs/University Courses:** Look for courses focusing on specific areas like Deep Learning, Computer Vision, Natural Language Processing, or MLOps (Machine Learning Operations), which will be increasingly important as ML systems scale.\n",
      "    *   **Research Papers (via arXiv, Google Scholar):** Stay informed about the latest advancements. While challenging, reading summaries and recent papers (especially in areas like Generative AI, Transformers, or RLHF) will be key for understanding the forefront heading towards 2025.\n",
      "\n",
      "4.  **Community & Further Learning:**\n",
      "    *   **Reddit (r/MachineLearning, r/datascience):** Engage with discussions, get answers to specific questions, and stay updated on industry news and trends.\n",
      "    *   **YouTube Channels (e.g., Google I/O, PyCon, 3Blue1Brown):** Visual explanations and talks from experts help solidify understanding and provide insights into industry trends relevant to 2025.\n",
      "\n",
      "This roadmap combines structured learning, practical application, and staying current with the rapidly evolving field, positioning learners well for mastering machine learning by 2025. Remember to supplement with coding practice and project building!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "MODEL = \"deepseek-r1:8b\"\n",
    "question = \"What are the best resources to learn machine learning in 2025?\"\n",
    "\n",
    "# Step 1: Initialize the reasoning model via ChatOllama\n",
    "llm = ChatOllama(model=MODEL, temperature=0.7)\n",
    "\n",
    "# Step 2: Build the agent with tool access (DuckDuckGo Search) and function-calling interface (initialize_agent)\n",
    "agent = initialize_agent([search_tool], llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "\n",
    "# Step 3: Ask a query and let the agent search + reason to produce an answer\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "result = agent.run(question)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Final Answer:\\n{result}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1c3f7",
   "metadata": {},
   "source": [
    "# Optional (Multi-agent Deep Research)\n",
    "Instead of a single multi-step agent, you can design multiple collaborating agents such as a Planner, Searcher, Summarizer, and Verifier that pass information and refine each other’s outputs. This setup improves robustness, diversity of reasoning, and division of labor.\n",
    "\n",
    "Try building a simple setup with 2–3 agents that share goals and messages, for example Planner → Researcher → Writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59abf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the best resources to learn ML in 2025?\n",
      "\n",
      "Starting 3 parallel research agents...\n",
      "============================================================\n",
      "\n",
      "[Agent 1] Starting research...\n",
      "\n",
      "[Agent 2] Starting research...\n",
      "\n",
      "[Agent 3] Starting research...\n",
      "[Agent 2] Completed!\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "def run_single_research(query, agent_id):\n",
    "    \"\"\"Run a single research agent and return its answer.\"\"\"\n",
    "    print(f\"\\n[Agent {agent_id}] Starting research...\")\n",
    "\n",
    "    # Initialize model and agent for this thread\n",
    "    llm = ChatOllama(model=\"deepseek-r1:8b\", temperature=0.7)\n",
    "    agent = initialize_agent(\n",
    "        [search_tool],\n",
    "        llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=False,  # Set to False to avoid cluttered output\n",
    "        handle_parsing_errors=True  # Handle deepseek-r1's reasoning format\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = agent.run(query)\n",
    "        print(f\"[Agent {agent_id}] Completed!\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"[Agent {agent_id}] Error: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "def parallel_research(query, n=3):\n",
    "    # Run n independent research runs in parallel and return their answers.\n",
    "    # Steps: use ThreadPoolExecutor; submit n calls to your agent/search pipeline; gather results in order.\n",
    "\n",
    "    # Run n independent research runs in parallel and return their answers.\n",
    "    print(f\"Starting {n} parallel research agents...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Use ThreadPoolExecutor to run multiple agents in parallel\n",
    "    with ThreadPoolExecutor(max_workers=n) as executor:\n",
    "        # Submit n tasks\n",
    "        futures = [executor.submit(run_single_research, query, i+1) for i in range(n)]\n",
    "\n",
    "        # Gather results in order\n",
    "        answers = [future.result() for future in futures]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"All agents completed!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    return answers\n",
    "\n",
    "# Run parallel research\n",
    "query = \"What are the best resources to learn ML in 2025?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "answers = parallel_research(query, n=3)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS FROM 3 PARALLEL AGENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, answer in enumerate(answers, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Agent {i} Answer (first 800 chars):\")\n",
    "    print(f\"{'='*60}\")\n",
    "    # Show first 800 chars to see variation\n",
    "    print(answer[:800] + \"...\" if len(answer) > 800 else answer)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507d0a4",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "* Practised various inference‑time reasoning methods\n",
    "* Gained intuition about training reasoning models\n",
    "* You have built a **deep-research agent**: reasoning model like deep-seek r1 + ReAct-style agent + tool use (web search)\n",
    "* Try adding more tools, and extending the deep-research to a multi-agent system: many agents researching web in parallel.\n",
    "\n",
    "\n",
    "👏 **Great job!** Take a moment to celebrate. The techniques you implemented here power many production agents and chatbots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_research",
   "language": "python",
   "name": "deep_research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
